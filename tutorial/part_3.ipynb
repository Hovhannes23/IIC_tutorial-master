{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Part 3: Practice"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "This is the last part of IIC tutorial. Here we try to use it for clustering and semi-supervised classification of MNIST.\n",
    "Some useful functions are implemented in [utils](https://github.com/vandedok/IIC_tutorial/blob/master/tutorial/utils.py) and in [preprocess](https://github.com/vandedok/IIC_tutorial/blob/master/tutorial/preprocess.py) modules. Feel free to look there if you want to understand how everything works in detail."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "If you a working in Google colab you need to do  a coouple of additional moves. First, go to \"Runtime\" menu, click on \"Change runtme type\", and select GPU option in \"Runtime type\n",
    "Hardware accelerator\" menu. After this uncomment and run the cell below. When the execution is finished, restart the runtime."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# !curl https://raw.githubusercontent.com/vandedok/IIC_tutorial/master/tutorial/requirements_colab.txt --output requirements_colab.txt\n",
    "# !curl https://raw.githubusercontent.com/vandedok/IIC_tutorial/master/tutorial/utils.py --output utils.py\n",
    "# !curl https://raw.githubusercontent.com/vandedok/IIC_tutorial/master/tutorial/preprocess.py --output preprocess.py\n",
    "# !pip install -r requirements_colab.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import random\n",
    "import os\n",
    "import sys\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "import warnings\n",
    "\n",
    "warnings.simplefilter(action=\"ignore\", category=FutureWarning)\n",
    "# warnings.simplefilter(action='ignore', category=UserWarning)\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch import nn\n",
    "import albumentations as A\n",
    "import torchvision.models as models\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "from sklearn.metrics import adjusted_rand_score, accuracy_score\n",
    "from sklearn.metrics.cluster import homogeneity_score, completeness_score\n",
    "\n",
    "from utils import (\n",
    "    visualize_augmentations,\n",
    "    weight_init,\n",
    "    print_while_trainig,\n",
    "    get_cluster_labeling,\n",
    "    visualise_clusetering_results,\n",
    "    stratified_split,\n",
    ")\n",
    "from utils import create_mapping, print_mapping\n",
    "from preprocess import create_MNIST_arrays, manually_download_MNIST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# This  should  enable automatic downloading of MNIST\n",
    "from six.moves import urllib\n",
    "\n",
    "opener = urllib.request.build_opener()\n",
    "opener.addheaders = [(\"User-agent\", \"Mozilla/5.0\")]\n",
    "urllib.request.install_opener(opener)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "<torch._C.Generator at 0x7f2727c24dd0>"
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Fix torch randomization for reproducability\n",
    "torch.manual_seed(42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Preprocessing the data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "First of all we define the augmentations, which are one of the key elements of IIC approach. I use Albumentations library to compose horizontal flips, rotations, perspective changes, superpixels, noise, brightness and contrast transforms. Each of theses transforms can be applied with a certain probability to an input image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "alb_transforms = A.Compose(\n",
    "    [\n",
    "        A.HorizontalFlip(),\n",
    "        A.Rotate(limit=40, p=0.7),\n",
    "        A.IAAPerspective(scale=(0.1, 0.1), p=0.7),\n",
    "        A.IAASuperpixels(p_replace=0.3, p=0.7),\n",
    "        A.IAAAdditiveGaussianNoise(scale=(0.1 * 255, 0.2 * 255), p=0.7),\n",
    "        A.RandomBrightnessContrast(brightness_limit=0.5, contrast_limit=0.6, p=0.7),\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Now we need to define a dataset. We can do it in a usual way, by inheriting MNIST dataset class and editing the transforms call in ```__getitem__``` method like [here](https://pytorch.org/tutorials/beginner/data_loading_tutorial.html). However this approach has a huge drawback -- at each call a new augmentation is computed, so during the training a lot of time is spent not on the forward and backward runs, but on getting an augmented batch. To avoid this, we precompute the augmentations in advance  and save them in RAM. It is done in the ```RAMAugMNIST``` class, which you can see below. In fact all the preprocessing is done in ```create_MNIST_arrays```  function from [preprocessing module](link_to_preprocessing_module)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "If you want to see, how  it is implemented, feel free look at the  [preprocessing module](link_to_preprocessing_module). However for this tutorial it's sufficient to know, that at this stage several numpy arrays are created and stored in RAM: one containing the original MNIST, one containing the labels and several ones containing the augmented versions of MNIST. Now let's define the dataset dir:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "outputs": [],
   "source": [
    "class RAMAugMNIST(Dataset):\n",
    "    \"\"\"The dataset contatining the original and augmented data in RAM\n",
    "\n",
    "    Attributes\n",
    "    ----------\n",
    "    original_dataset : numpy.ndarray\n",
    "        shape (N,...) where N is the number of data samples, and \"...\" stands for\n",
    "        the shape of a single data sample. The array with riginal images.\n",
    "    labels : numpy.ndarray\n",
    "        shape (N,). Array of class labels\n",
    "    aug_datasets : list of numpy.ndarray\n",
    "        list of augmented datasets with the same shape as original_dataset\n",
    "    aug_number : int\n",
    "        number of augmentations\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        augs_files=None,\n",
    "        alb_transforms=A.Compose([]),\n",
    "        aug_number=5,\n",
    "        target_dir=\"./dataset/\",\n",
    "        aug_batch_size=1024,\n",
    "        aug_num_workers=6,\n",
    "    ):\n",
    "        \"\"\"Datasetataset initialisation\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        augs_files : list of str\n",
    "            list of pathes to binary np files with mnist augmentations. If this parameter is specifed,\n",
    "            there is no need to pass other parameters\n",
    "        alb_transforms : albumentations.core.composition.Compose\n",
    "            a composition of Albumentations transforms. Ignored if augs_files is specified.\n",
    "        aug_number : int\n",
    "            number of augmentations to make. Ignored if augs_files is specified.\n",
    "        target_dir : str\n",
    "            dir to store the dataset. Ignored if augs_files is specified.\n",
    "        batch_size : int\n",
    "            size of batch used in augmentation. Ignored if augs_files is specified.\n",
    "        num_workers : int\n",
    "            number of CPU threads to use in augmentations. Ignored if augs_files is specified.\n",
    "\n",
    "        \"\"\"\n",
    "\n",
    "        if augs_files is not None:\n",
    "            aug_number = 0\n",
    "\n",
    "        self.original_dataset, self.labels, self.aug_datasets = create_MNIST_arrays(\n",
    "            alb_transforms=alb_transforms,\n",
    "            aug_number=aug_number,\n",
    "            target_dir=target_dir,\n",
    "            batch_size=aug_batch_size,\n",
    "            num_workers=aug_num_workers,\n",
    "        )\n",
    "        self.aug_number = aug_number\n",
    "\n",
    "        if augs_files is not None:\n",
    "            print(\"Loading augmented datasets...\", end=\" \")\n",
    "            self.aug_datasets = [np.load(x) for x in augs_files]\n",
    "            self.aug_number = len(augs_files)\n",
    "            print(\"Done!\")\n",
    "\n",
    "    def save_augs(self, dataset_dir):\n",
    "        \"\"\"saves augmentations as binary np files\"\"\"\n",
    "\n",
    "        print(\"Saving augs in %s...\" % dataset_dir, end=\" \")\n",
    "        for aug_idx, aug_array in enumerate(self.aug_datasets):\n",
    "            file_path = os.path.join(dataset_dir, \"mnist_aug_\" + str(aug_idx) + \".np\")\n",
    "            with open(file_path, \"wb\") as file:\n",
    "                np.save(file, aug_array)\n",
    "        print(\"Done!\")\n",
    "\n",
    "    def __len__(self):\n",
    "        \"\"\"returns the length of the dataset\"\"\"\n",
    "        return self.original_dataset.shape[0]\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        \"\"\"Returns the dataset sample and index idx\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        return_dict : dict\n",
    "            dict with the following keys:\n",
    "            \"original\" : numpy.ndarray\n",
    "                original image taken from self.original_dataset\n",
    "            \"aug\" : numpy.ndarray\n",
    "                augmented image taken randomly from one of self.aug_datasets\n",
    "            \"label\" : int\n",
    "                run label of the image taken form self.labels\n",
    "        \"\"\"\n",
    "        type(idx)\n",
    "        original_image = np.array(\n",
    "            self.original_dataset[idx : idx + 1, :, :], copy=True, dtype=np.float32\n",
    "        )\n",
    "        label = np.array(self.labels[idx], copy=True, dtype=np.float32)\n",
    "\n",
    "        return_dict = {\"original\": original_image, \"label\": label}\n",
    "\n",
    "        if self.aug_number > 0:\n",
    "            aug_version = int(self.aug_number * random.random())\n",
    "            aug_image = np.array(\n",
    "                self.aug_datasets[aug_version][idx : idx + 1, :, :],\n",
    "                copy=True,\n",
    "                dtype=np.float32,\n",
    "            )\n",
    "            return_dict[\"aug\"] = aug_image\n",
    "\n",
    "        return return_dict"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "outputs": [],
   "source": [
    "DATASET_DIR = \"./dataset/\""
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "And create a dataset. I recommend to use 10 different augmentation (the ```aug_number``` parameter). However, if you don't want to wait it's possible to use less number of augmentations, say 5, and get a decent result:"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "<span style=\"font-size:larger;\">WARNING: this cell can take several minutes to run! A simple way to improve the performance is to set num_workers equal to your computer CPU cores (2 for google colab) </span>"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading MNIST... Done!\n"
     ]
    }
   ],
   "source": [
    "manually_download_MNIST(DATASET_DIR)\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading https://drive.google.com/file/d/10mRS2za8-xflqsKMU5Hp_4l6njhjvbmr/view?usp=sharing to ./dataset/AlbMNIST/raw/view?usp=sharing\n"
     ]
    },
    {
     "data": {
      "text/plain": "0it [00:00, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "be329f17f7e84365b2b03f4c77c5deca"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./dataset/AlbMNIST/raw/view?usp=sharing to ./dataset/AlbMNIST/raw\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Extraction of ./dataset/AlbMNIST/raw/view?usp=sharing not supported",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mValueError\u001B[0m                                Traceback (most recent call last)",
      "\u001B[0;32m<ipython-input-40-775e47879115>\u001B[0m in \u001B[0;36m<module>\u001B[0;34m\u001B[0m\n\u001B[0;32m----> 1\u001B[0;31m dataset_np = RAMAugMNIST(\n\u001B[0m\u001B[1;32m      2\u001B[0m     \u001B[0malb_transforms\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0malb_transforms\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m      3\u001B[0m     \u001B[0maug_number\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0;36m5\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m      4\u001B[0m     \u001B[0mtarget_dir\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0mDATASET_DIR\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m      5\u001B[0m     \u001B[0maug_batch_size\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0;36m1024\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m<ipython-input-38-904b1b272bf0>\u001B[0m in \u001B[0;36m__init__\u001B[0;34m(self, augs_files, alb_transforms, aug_number, target_dir, aug_batch_size, aug_num_workers)\u001B[0m\n\u001B[1;32m     47\u001B[0m             \u001B[0maug_number\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0;36m0\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     48\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m---> 49\u001B[0;31m         self.original_dataset, self.labels, self.aug_datasets = create_MNIST_arrays(\n\u001B[0m\u001B[1;32m     50\u001B[0m             \u001B[0malb_transforms\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0malb_transforms\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     51\u001B[0m             \u001B[0maug_number\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0maug_number\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/Desktop/IIC_tutorial-master/tutorial/preprocess.py\u001B[0m in \u001B[0;36mcreate_MNIST_arrays\u001B[0;34m(alb_transforms, aug_number, target_dir, batch_size, num_workers)\u001B[0m\n\u001B[1;32m    212\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    213\u001B[0m     \u001B[0;31m# dataset_alb = AlbMNIST(os.path.join(target_dir, \"MNIST\"), download=True)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 214\u001B[0;31m     \u001B[0mdataset_alb\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mAlbMNIST\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mos\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mpath\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mjoin\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mtarget_dir\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mdownload\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0;32mTrue\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    215\u001B[0m     dataloader = DataLoader(\n\u001B[1;32m    216\u001B[0m         \u001B[0mdataset_alb\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mbatch_size\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0mlen\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mdataset_alb\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mshuffle\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0;32mFalse\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mnum_workers\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0mnum_workers\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/Desktop/IIC_tutorial-master/tutorial/preprocess.py\u001B[0m in \u001B[0;36m__init__\u001B[0;34m(self, alb_transforms, *args, **kwargs)\u001B[0m\n\u001B[1;32m     16\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     17\u001B[0m     \u001B[0;32mdef\u001B[0m \u001B[0m__init__\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mself\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m*\u001B[0m\u001B[0margs\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0malb_transforms\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0;32mNone\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m**\u001B[0m\u001B[0mkwargs\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m---> 18\u001B[0;31m         \u001B[0msuper\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m__init__\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m*\u001B[0m\u001B[0margs\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m**\u001B[0m\u001B[0mkwargs\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m     19\u001B[0m         \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0malb_transforms\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0malb_transforms\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     20\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/Desktop/IIC_tutorial-master/venv/lib/python3.8/site-packages/torchvision/datasets/mnist.py\u001B[0m in \u001B[0;36m__init__\u001B[0;34m(self, root, train, transform, target_transform, download)\u001B[0m\n\u001B[1;32m     87\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     88\u001B[0m         \u001B[0;32mif\u001B[0m \u001B[0mdownload\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m---> 89\u001B[0;31m             \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mdownload\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m     90\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     91\u001B[0m         \u001B[0;32mif\u001B[0m \u001B[0;32mnot\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_check_exists\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/Desktop/IIC_tutorial-master/venv/lib/python3.8/site-packages/torchvision/datasets/mnist.py\u001B[0m in \u001B[0;36mdownload\u001B[0;34m(self)\u001B[0m\n\u001B[1;32m    158\u001B[0m         \u001B[0;32mfor\u001B[0m \u001B[0murl\u001B[0m \u001B[0;32min\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mresources\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    159\u001B[0m             \u001B[0mfilename\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0murl\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mrpartition\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m'/'\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0;36m2\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 160\u001B[0;31m             \u001B[0mdownload_and_extract_archive\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0murl\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mdownload_root\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mraw_folder\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mfilename\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0mfilename\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    161\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    162\u001B[0m         \u001B[0;31m# process and save as torch files\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/Desktop/IIC_tutorial-master/venv/lib/python3.8/site-packages/torchvision/datasets/utils.py\u001B[0m in \u001B[0;36mdownload_and_extract_archive\u001B[0;34m(url, download_root, extract_root, filename, md5, remove_finished)\u001B[0m\n\u001B[1;32m    258\u001B[0m     \u001B[0marchive\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mos\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mpath\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mjoin\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mdownload_root\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mfilename\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    259\u001B[0m     \u001B[0mprint\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m\"Extracting {} to {}\"\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mformat\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0marchive\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mextract_root\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 260\u001B[0;31m     \u001B[0mextract_archive\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0marchive\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mextract_root\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mremove_finished\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    261\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    262\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/Desktop/IIC_tutorial-master/venv/lib/python3.8/site-packages/torchvision/datasets/utils.py\u001B[0m in \u001B[0;36mextract_archive\u001B[0;34m(from_path, to_path, remove_finished)\u001B[0m\n\u001B[1;32m    234\u001B[0m             \u001B[0mz\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mextractall\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mto_path\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    235\u001B[0m     \u001B[0;32melse\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 236\u001B[0;31m         \u001B[0;32mraise\u001B[0m \u001B[0mValueError\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m\"Extraction of {} not supported\"\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mformat\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mfrom_path\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    237\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    238\u001B[0m     \u001B[0;32mif\u001B[0m \u001B[0mremove_finished\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;31mValueError\u001B[0m: Extraction of ./dataset/AlbMNIST/raw/view?usp=sharing not supported"
     ]
    }
   ],
   "source": [
    "dataset_np = RAMAugMNIST(\n",
    "    alb_transforms=alb_transforms,\n",
    "    aug_number=5,\n",
    "    target_dir=DATASET_DIR,\n",
    "    aug_batch_size=1024,\n",
    "    aug_num_workers=2,\n",
    ")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Now we perform the stratified train-val split of the dataset. This is needed for the semi-supervised classification setting. The validation part will be small -- only 600 images. We assume, that the train part has no labels so we are are not going to use them. Stratification is needed to make sure that each class is represented equally in the validation part."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "tags": []
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'dataset_np' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mNameError\u001B[0m                                 Traceback (most recent call last)",
      "\u001B[0;32m<ipython-input-62-6d90e489eb27>\u001B[0m in \u001B[0;36m<module>\u001B[0;34m\u001B[0m\n\u001B[0;32m----> 1\u001B[0;31m \u001B[0mdataset_train\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mdataset_val\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mstratified_split\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mdataset_np\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mtrain_size\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0;36m0.99\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m",
      "\u001B[0;31mNameError\u001B[0m: name 'dataset_np' is not defined"
     ]
    }
   ],
   "source": [
    "dataset_train, dataset_val = stratified_split(dataset_np, train_size=0.99)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Define the dataloaders:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'dataset_train' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mNameError\u001B[0m                                 Traceback (most recent call last)",
      "\u001B[0;32m<ipython-input-32-609348b774bc>\u001B[0m in \u001B[0;36m<module>\u001B[0;34m\u001B[0m\n\u001B[1;32m      1\u001B[0m \u001B[0mBATCH_SIZE\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0;36m2048\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m      2\u001B[0m dataloader_train = DataLoader(\n\u001B[0;32m----> 3\u001B[0;31m     \u001B[0mdataset_train\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mbatch_size\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0mBATCH_SIZE\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mshuffle\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0;32mTrue\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mnum_workers\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0;36m16\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m      4\u001B[0m )\n\u001B[1;32m      5\u001B[0m dataloader_val = DataLoader(\n",
      "\u001B[0;31mNameError\u001B[0m: name 'dataset_train' is not defined"
     ]
    }
   ],
   "source": [
    "BATCH_SIZE = 2048\n",
    "dataloader_train = DataLoader(\n",
    "    dataset_train, batch_size=BATCH_SIZE, shuffle=True, num_workers=16\n",
    ")\n",
    "dataloader_val = DataLoader(\n",
    "    dataset_val, batch_size=BATCH_SIZE, shuffle=True, num_workers=16\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "It's useful to see how our augmentations look. It can be done with the ```visualize_augmentations``` from [utils](https://github.com/vandedok/IIC_tutorial/blob/master/tutorial/utils.py) module. Each run will fetch random augmentations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'dataset_val' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mNameError\u001B[0m                                 Traceback (most recent call last)",
      "\u001B[0;32m<ipython-input-33-c3d3233fd6ce>\u001B[0m in \u001B[0;36m<module>\u001B[0;34m\u001B[0m\n\u001B[0;32m----> 1\u001B[0;31m \u001B[0mvisualize_augmentations\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mdataset_val\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0msamples\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0;36m6\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m",
      "\u001B[0;31mNameError\u001B[0m: name 'dataset_val' is not defined"
     ]
    }
   ],
   "source": [
    "visualize_augmentations(dataset_val, samples=6)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Great! We successfully  preprocessed the data and ready to build a model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## The model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "It's time to define a clustering model based on resnet backbone. This is a really basic CV model with the only unusual part being the presence of two fully connected layers: ```clustering_head``` and ```overclustering_head```overclustering_head. The latter one is needed to improve the learning process (see <a href=\"https://arxiv.org/abs/1807.06653\">original paper</a>  or appendix in [Part 1](https://github.com/vandedok/IIC_tutorial/blob/master/tutorial/part_1.md) of this tutorial)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Let's define a ResNet backbone, based, say, on  ResNat18 model. In IIC approach we don't expect the model to have any prior knowledge, so we set \"pretrained\" parameter to False."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "resnet = models.resnet18(pretrained=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "First we want to get bare CNN backbone. This means, that we need to cut a couple of layers from the top of the model. To see which ones we need to cut, lest print several last layers:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "list(resnet.children())[-3:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "The layers to cut are AdaptiveAvgPool2d and Linear:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "modules_to_keep = list(resnet.children())[:-2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "The original ResNet18 model is designed to process to color images. We can adapt it to grayscale images by modifying the first layer:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "print(\"The first layer:\", modules_to_keep[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "All we need to do is to redefine this module with the same parameters except for the ```in_channels```:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "modules_to_keep[0] = nn.Conv2d(\n",
    "    1, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Now let's append Flatten layer and compose a backbone to see how many output features it has."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "modules_to_keep.append(nn.Flatten())\n",
    "backbone = nn.Sequential(*modules_to_keep)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "To see the number of output features we define a batch of images. To speed up the computation we leave only tree images in our batch:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "batch = next(iter(dataloader_train))[\"original\"]\n",
    "batch = batch[0:3]\n",
    "print(\"Batch shape:\", batch.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "It's time to see how many features our backbone outputs:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "print(\"Output shape:\", backbone(batch).shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "It has 512 features. We will use it to define clustering and overclustering heads:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "final_features = 512\n",
    "cluster_head = nn.Linear(final_features, 10)\n",
    "overcluster_head = nn.Linear(final_features, 50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Now let's gather everything into new ```nn.Module```:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "class ResNetClusterisator(nn.Module):\n",
    "    \"\"\"Clusterisator for IIC based on ResNet18 backbone\"\"\"\n",
    "\n",
    "    def __init__(self):\n",
    "        super(ResNetClusterisator, self).__init__()\n",
    "        # The number of output features we precomputed earlier\n",
    "        final_features = 512\n",
    "\n",
    "        # Define the backbone:\n",
    "        resnet = models.resnet18(pretrained=False)\n",
    "        modules = list(resnet.children())[:-2]\n",
    "        modules[0] = nn.Conv2d(\n",
    "            1, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False\n",
    "        )\n",
    "        modules.append(nn.Flatten())\n",
    "        self.backbone = nn.Sequential(*modules)\n",
    "\n",
    "        # Define clustering and overculstering heads\n",
    "        self.cluster_head = nn.Linear(final_features, 10)\n",
    "        self.overcluster_head = nn.Linear(final_features, 50)\n",
    "\n",
    "        # Define the softmax layer\n",
    "        self.softmax = nn.Softmax(dim=1)\n",
    "\n",
    "    def forward(self, x, overclustering=False):\n",
    "        \"\"\"Foward run. Can operate in both clustering an overclustering regimes\n",
    "\n",
    "        Paraneters\n",
    "        ----------\n",
    "        x : torch.tensor\n",
    "            input batch. The shape is supposed to be (B,1,28,28)\n",
    "            where B is batch size\n",
    "        overclustering : boolean\n",
    "            if True, the overclustering head is used\n",
    "            else the clustering head is used\n",
    "        \"\"\"\n",
    "        x = self.backbone(x)\n",
    "        if overclustering:\n",
    "            x = self.overcluster_head(x)\n",
    "        else:\n",
    "            x = self.cluster_head(x)\n",
    "\n",
    "        return self.softmax(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Now let's transfer our model to gpu and initialize the weights. Note, that in general different initializations can result in significantly different performance. Here we suppressed this effect by setting a manual seed at the beginning of the notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(\"Using %s.\" % device)\n",
    "model = ResNetClusterisator()\n",
    "model.to(device)\n",
    "print(\"The model is transfered to %s.\" % device)\n",
    "model.apply(weight_init)\n",
    "print(\"The weights are Initialised.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Let's check that everything is fine by making a forward run:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "batch = next(iter(dataloader_train))[\"original\"]\n",
    "batch = batch.to(device)\n",
    "print(\"Model output shape in clustering mode:\", model(batch).shape)\n",
    "print(\"Model output shape in overclustering mode:\", model(batch).shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Fine! Let's proceed to the loss function."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Mutual information loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "The second ingredient of IIC is a mutual information loss function. This code is based on the [original paper implementation](https://github.com/xu-ji/IIC/blob/master/code/utils/cluster/IID_losses.py#L6) with a minor changes. The mathematical details of  mutual information loss can be found in [Part 2](https://github.com/vandedok/IIC_tutorial/blob/master/tutorial/part_2.md) of this tutorial."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "First we compute the estimation of the joint probability distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def compute_joint(x_out, x_tf_out):\n",
    "    \"\"\"Estimate a joint probability distribution\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    x_out : torch.tensor\n",
    "        shape (B,C) where B is a batch size, C is a number of classes\n",
    "        probabilities for the original batch\n",
    "    x_out_tf: torch.tensor\n",
    "        the same shape as x_out\n",
    "        probabilities for the trasformed batch\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    p_i_j : torch.tensor\n",
    "        shape (C,C) where C is a number of classes (the same as in x_out)\n",
    "        joint probabilities\n",
    "\n",
    "    \"\"\"\n",
    "    # multiplying probabilities\n",
    "    p_i_j = x_out.unsqueeze(2) * x_tf_out.unsqueeze(1)  # bn, k, k\n",
    "\n",
    "    # suminng over the batch_size\n",
    "    p_i_j = p_i_j.mean(dim=0)\n",
    "\n",
    "    # Symmetriztion\n",
    "    p_i_j = (p_i_j + p_i_j.t()) / 2.0\n",
    "\n",
    "    return p_i_j"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "And than the mutual information. Several tricks are used here. \n",
    "\n",
    "The first one is the regularization of joint probabilities. Recall, that what we compute mutual information we take the log of joints. When some joint probabilities $p_{ij}$ are small, $\\log p_{ij}$ may be too large to be stored in float, so the NaN value will be returned. To avoid this we take a small value $\\epsilon$ and replace with it all the joints which are less than $\\epsilon$:\n",
    "\n",
    "$$\\forall p_{ij} < \\epsilon: \\log(p_{ij}) \\quad\\mathrm{is~replaced~with}\\quad \\log(\\epsilon)$$\n",
    "\n",
    "This is mathematically correct, as those logarithms come only in  such expressions as $p_{ij}\\log(p_{ij})$, which goes to zero as $p_{ij}$ goes to zero.\n",
    "\n",
    "The second one is the additional minus sign on in front of the mutual information. As we applied it, we need to minimize, not to maximize our loss."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def IID_loss(x_out, x_tf_out, lamb=1.0, EPS=sys.float_info.epsilon):\n",
    "    \"\"\"Compute mutual information loss. Theo overall minus sign is added so the loss should be minimized.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    x_out : torch.tensor\n",
    "        shape (B,C) where B is a batch size, C is a number of classes\n",
    "        probabilities for the original batch\n",
    "    x_out_tf: torch.tensor\n",
    "        the same shape as x_out\n",
    "        probabilities for the trasformed batch\n",
    "    lambd : float\n",
    "        parameter modyfing the loss.\n",
    "        Larger lamb generally pushes the model towards putting\n",
    "        spreading the samples to the different clusters of equal sizes.\n",
    "        Smaller lambd pushes the model towards putting similar images to one cluster\n",
    "    EPS : float\n",
    "        parameter to regulerize small probabilities\n",
    "\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    loss : torch.tensor\n",
    "        shape (1,). Mutual information loss\n",
    "\n",
    "    \"\"\"\n",
    "    _, num_classes = x_out.size()\n",
    "\n",
    "    # Estimate joint probabilities\n",
    "    p_i_j = compute_joint(x_out, x_tf_out)\n",
    "    assert p_i_j.size() == (num_classes, num_classes)\n",
    "\n",
    "    # Trick to avoid NaN losses for small p_i_j\n",
    "    mask = ((p_i_j > EPS).data).type(torch.float32)\n",
    "    p_i_j = p_i_j * mask + EPS * (1 - mask)\n",
    "\n",
    "    # Computing the marginals\n",
    "    p_i = p_i_j.sum(dim=1).view(num_classes, 1).expand(num_classes, num_classes)\n",
    "    p_j = p_i_j.sum(dim=0).view(1, num_classes).expand(num_classes, num_classes)\n",
    "\n",
    "    # Compute the mutual information\n",
    "    loss = -p_i_j * (torch.log(p_i_j) - lamb * torch.log(p_j) - lamb * torch.log(p_i))\n",
    "\n",
    "    loss = torch.sum(loss)\n",
    "\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Thats all about the loss implemetation. Now let's go to the traning!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Let's take a look at IIC forward run. Our train dataloader will give us a batch with original images, transfomed images and labels:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "batch = next(iter(dataloader_train))\n",
    "print(\"Batch entities:\", batch.keys(), end=\"\\n\\n\")\n",
    "print(\"Original images batch shape:     {0}\".format(batch[\"original\"].shape))\n",
    "print(\"Transformed images batch shape:  {0}\".format(batch[\"aug\"].shape))\n",
    "print(\"Labels batch shape:              {0}\".format(batch[\"label\"].shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "We are not using labels in training. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "After fetching the batches we transfer them to the gpu:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "inputs = batch[\"original\"]\n",
    "inputs_tf = batch[\"aug\"]\n",
    "\n",
    "inputs = inputs.to(device=device)\n",
    "inputs_tf = inputs_tf.to(device=device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "And than computing the outputs, the loss and make a backward run:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "overclustering = False\n",
    "lamb = 1.0\n",
    "outputs = model(inputs, overclustering)\n",
    "outputs_tf = model(inputs_tf, overclustering)\n",
    "loss = IID_loss(outputs, outputs_tf, lamb=lamb)\n",
    "print(loss.data.cpu().numpy())\n",
    "loss.backward()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "That's it! "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Before rushing into training we need a funtion to evaluate the loss. It just iterates over dataloader, makes the forward run and computes  the mean loss:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def evaluate(\n",
    "    model, dataloader, overclustering=False, lamb=1.0, device=torch.device(\"cpu\")\n",
    "):\n",
    "    \"\"\"Calculates the model mean loss. The average is taken over the batches.\"\"\"\n",
    "\n",
    "    losses = []\n",
    "    # switch model to the eval state to prevent the training\n",
    "    model.eval()\n",
    "\n",
    "    for i, batch in enumerate(dataloader):\n",
    "\n",
    "        # forward run\n",
    "        inputs = batch[\"original\"]\n",
    "        inputs_tf = batch[\"aug\"]\n",
    "        with torch.no_grad():\n",
    "\n",
    "            inputs = inputs.to(device=device)\n",
    "            inputs_tf = inputs_tf.to(device=device)\n",
    "\n",
    "            outputs = model(inputs, overclustering)\n",
    "            outputs_tf = model(inputs_tf, overclustering)\n",
    "\n",
    "        loss = IID_loss(outputs, outputs_tf, lamb=lamb)\n",
    "\n",
    "        # combining the losses for all batches into a single list\n",
    "        losses.append(loss.data.cpu().numpy())\n",
    "\n",
    "    # output the mean loss\n",
    "    return np.mean(losses)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Recall, that in [Part 1](https://github.com/vandedok/IIC_tutorial/blob/master/tutorial/part_1.md) we discussed, that our model can greatly benefit from switching between clustering and overculstering. Here we implement it in a following way:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def choose_clustering_regime(epoch, overcluster_period, overcluster_ratio):\n",
    "    \"\"\"Choice of the clustering regime based on the epoch number\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    epoch : int\n",
    "        current epoch number\n",
    "    overcluster_period : int\n",
    "        total period for both clustering and overclustering\n",
    "    overcluster_ratio : float\n",
    "        a fraction of time to spend on overclustering\n",
    "    \"\"\"\n",
    "\n",
    "    if (\n",
    "        overcluster_period is not None\n",
    "        and epoch % overcluster_period < overcluster_period * overcluster_ratio\n",
    "    ):\n",
    "        return True\n",
    "    else:\n",
    "        return False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Now it's time to combine the forward run and the backward run in a training loop. I have also put some printing stuff here, so you can observe loss evolution during the training.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def IIC_train(\n",
    "    modeldataset,\n",
    "    dataloader,\n",
    "    optimizer,\n",
    "    epochs=100,\n",
    "    device=torch.device(\"cpu\"),\n",
    "    eval_every=5,\n",
    "    lamb=1.0,\n",
    "    overcluster_period=20,\n",
    "    overcluster_ratio=0.5,\n",
    "):\n",
    "    \"\"\"IIC training loop\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    model : ResNetClusterisator\n",
    "        the IIC model to train\n",
    "    dataloader : torch.utils.data.dataloader.DataLoader\n",
    "        dataloader to fetch the data\n",
    "    optimizer : torch.optim.optimier like\n",
    "        your favourite optimzer\n",
    "    epochs : int\n",
    "        total number of epoches\n",
    "    device : torch.device\n",
    "        device which sould perform the trainig\n",
    "    eval_every : int\n",
    "        the freqency of evaluation\n",
    "    lamb : float\n",
    "        paramter to modyfy IID_loss (see IID_loss)\n",
    "    overcluster_period : int\n",
    "        total period for both clustering and overclustering\n",
    "    overcluster_ratio : float\n",
    "        a fraction of time to spend on overclustering\n",
    "    \"\"\"\n",
    "\n",
    "    # Lists to store epochs numbers and losses for visualisation\n",
    "    epochs_list = []\n",
    "    loss_history = []\n",
    "    loss_history_overclustering = []\n",
    "\n",
    "    # Variables for best losses\n",
    "    best_cluster_loss = 0\n",
    "    best_overcluster_loss = 0\n",
    "\n",
    "    # Progress bar instance\n",
    "    pbar = tqdm(total=len(dataloader), leave=False, desc=\"Epoch\")\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "\n",
    "        # Switching the model to train mode\n",
    "        model.train()\n",
    "        # Define where the epoch is dedicated to clustering or overclustering\n",
    "        overclustering = choose_clustering_regime(\n",
    "            epoch, overcluster_period, overcluster_ratio\n",
    "        )\n",
    "\n",
    "        # Reseting the progress bar\n",
    "        pbar.reset()\n",
    "        pbar.desc = \"Epoch #%i\" % epoch\n",
    "\n",
    "        for i, batch in enumerate(dataloader):\n",
    "\n",
    "            # Nullifing the gradients\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            # Forward run\n",
    "            inputs = batch[\"original\"]\n",
    "            inputs_tf = batch[\"aug\"]\n",
    "\n",
    "            inputs = inputs.to(device=device)\n",
    "            inputs_tf = inputs_tf.to(device=device)\n",
    "\n",
    "            outputs = model(inputs, overclustering)\n",
    "            outputs_tf = model(inputs_tf, overclustering)\n",
    "            loss = IID_loss(outputs, outputs_tf, lamb=lamb)\n",
    "\n",
    "            # Backward run\n",
    "            loss.backward()\n",
    "\n",
    "            # Updating the weights\n",
    "            optimizer.step()\n",
    "\n",
    "            # Updating the progreess bar\n",
    "            pbar.update(1)\n",
    "\n",
    "        # Evaluation section\n",
    "        if (epoch + 1) % eval_every == 0:\n",
    "\n",
    "            # Computing eval losses\n",
    "            loss_eval = evaluate(\n",
    "                model, dataloader, overclustering=False, lamb=lamb, device=device\n",
    "            )\n",
    "            loss_eval_overclustering = evaluate(\n",
    "                model, dataloader, overclustering=True, lamb=lamb, device=device\n",
    "            )\n",
    "\n",
    "            loss_history.append(loss_eval)\n",
    "            loss_history_overclustering.append(loss_eval_overclustering)\n",
    "            epochs_list.append(epoch)\n",
    "\n",
    "            # Saving the model with best evaluation loss\n",
    "            if loss_eval < best_cluster_loss:\n",
    "                best_cluster_loss = loss_eval\n",
    "                torch.save(model.state_dict(), \"best_loss_model\")\n",
    "\n",
    "            pbar.close()\n",
    "\n",
    "            # Visualising the training\n",
    "            print_while_trainig(epochs_list, loss_history, loss_history_overclustering)\n",
    "\n",
    "            pbar = tqdm(total=len(dataloader), leave=False, desc=\"Epoch\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Let's begin the training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "optimizer = torch.optim.Adam(\n",
    "    model.parameters(),\n",
    "    lr=4e-4,\n",
    "    betas=(0.9, 0.999),\n",
    "    eps=1e-08,\n",
    "    weight_decay=0,\n",
    "    amsgrad=False,\n",
    ")\n",
    "IIC_train(\n",
    "    model,\n",
    "    dataloader_train,\n",
    "    optimizer,\n",
    "    device=device,\n",
    "    epochs=60,\n",
    "    lamb=1.2,\n",
    "    overcluster_period=20,\n",
    "    overcluster_ratio=0.5,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "You should see a couple non-monotonously decaying lines. When the model is in the clustering mode, overclusetring loss can grow and vice versa. However after about 60 epochs the clustering loss reaches plateau and the training can be stopped."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "It's time to evaluate our model performance. Firstly we load the model which showed the best loss on train data: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "model.load_state_dict(torch.load(\"best_loss_model\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Clustering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Than we compose two labelings -- the original one and the one which is outputted by the model. Note, that in a fair clustering setting the original labels are not available, so this method is applicable only in testing _clustering method_ on a labeled dataset. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "original_labels, cluster_labels = get_cluster_labeling(\n",
    "    model, dataloader_train, device=device\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "We visualize the results with a set of histograms. Each histograms corresponds to a certain original class and shows, how  clustering labels are distributed along this class. The best case is when all the histograms have a single huge bin. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "visualise_clusetering_results(original_labels, cluster_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "models performanceWe can also compute some clustering scores to get a numerical metrics of the clustering. Here I use [adjusted_rand_score](https://scikit-learn.org/stable/modules/generated/sklearn.metrics.adjusted_rand_score.html), [homogeneity_score](https://scikit-learn.org/stable/modules/generated/sklearn.metrics.homogeneity_score.html), [completeness_score](https://scikit-learn.org/stable/modules/generated/sklearn.metrics.completeness_score.html). The closer the values to the ones, the better:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "adj_score = adjusted_rand_score(cluster_labels, original_labels)\n",
    "hom_score = homogeneity_score(cluster_labels, original_labels)\n",
    "compl_score = completeness_score(cluster_labels, original_labels)\n",
    "print(\"Adjusted rand score: %.3f \" % adj_score)\n",
    "print(\"Homogeneity score: %.3f \" % adj_score)\n",
    "print(\"Completeness score: %.3f\" % compl_score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Semi-supervised classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "To evaluate the model in semi-supervised classification setting, we use our val dataloader, which fetches the data previously unseen by the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "original_labels, cluster_labels = get_cluster_labeling(\n",
    "    model, dataloader_val, device=device\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "We visualize the labels in the same way as before:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "visualise_clusetering_results(original_labels, cluster_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "To compute usual classification metrics, we need to create a mapping from cluster labels to original labels. Function ```create_mapping``` does it by assigning the most frequent class present in the cluster:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "cluster_mapping = create_mapping(original_labels, cluster_labels)\n",
    "cluster_labels_mapped = [cluster_mapping[x] for x in cluster_labels]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "The mapping is:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "print_mapping(cluster_mapping)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Now the largest bins should be at the places which correspond to the original labels:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "visualise_clusetering_results(original_labels, cluster_labels_mapped)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "The accuracy is:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "accuracy_score(original_labels, cluster_labels_mapped)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "If the training was done correctly the accuracy should be grater than 0.9. The autors of the <a href=\"https://arxiv.org/abs/1807.06653\">original paper</a> achieved the accuracy of 99.2%"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Conclusion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "If everything went well, by this line you have successfully trained and evaluated IIC model. Congrats!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}